{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "fe4fa27f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "df_attacks = pd.read_csv(\"DATA/attacks.csv\",encoding = \"ISO-8859-1\")\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import src.cleaning_functions as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b83f4c",
   "metadata": {},
   "source": [
    "MIS 3 HIPÓTESIS SON:\n",
    "- En 2018 hubo más ataques de tiburones tigre en el hemisferio sur que en 1990.\n",
    "- En México hay más ataques de tiburones blancos que en USA.\n",
    "- La mayoría de las víctimas que practican surf son mujeres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991d832",
   "metadata": {},
   "source": [
    "Por tanto, para verificar o refutar las 3 hipótesis planteadas, voy a utilizar las siguientes columnas:\n",
    "- Year\n",
    "- Country\n",
    "- Activity\n",
    "- Sex\n",
    "- Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bcfc1",
   "metadata": {},
   "source": [
    "Voy a proceder a eliminar las columnas del dataframe que, de primeras, no me van a ser de utilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7819e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks.drop([\"Case Number\",\"pdf\",\"href formula\",\"href\",\"Case Number.1\",\"Case Number.2\",\"original order\",\"Unnamed: 22\",\"Unnamed: 23\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8990116",
   "metadata": {},
   "source": [
    "Ahora la forma de mi df es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "33d65c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 15)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attacks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72fae2",
   "metadata": {},
   "source": [
    "Borro filas duplicadas y comprobamos que hemos pasado de 25723 a 6305 filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "993c5e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6302, 15)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borrado=df_attacks.drop_duplicates()\n",
    "borrado.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824efdf6",
   "metadata": {},
   "source": [
    "Borro las filas que sean enteras NaN. En este caso, tras comprobar el shape, veo que solo es una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1992c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6301, 15)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borrado.dropna(how=\"all\", inplace=True)\n",
    "borrado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb7878",
   "metadata": {},
   "source": [
    "Con \".info\" veo qué tipos de datos tengo y veo que todos son categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "cd8f4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6301 entries, 0 to 6301\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Date                    6301 non-null   object \n",
      " 1   Year                    6299 non-null   float64\n",
      " 2   Type                    6297 non-null   object \n",
      " 3   Country                 6251 non-null   object \n",
      " 4   Area                    5846 non-null   object \n",
      " 5   Location                5761 non-null   object \n",
      " 6   Activity                5757 non-null   object \n",
      " 7   Name                    6091 non-null   object \n",
      " 8   Sex                     5736 non-null   object \n",
      " 9   Age                     3471 non-null   object \n",
      " 10  Injury                  6273 non-null   object \n",
      " 11  Fatal (Y/N)             5762 non-null   object \n",
      " 12  Time                    2948 non-null   object \n",
      " 13  Species                 3463 non-null   object \n",
      " 14  Investigator or Source  6284 non-null   object \n",
      "dtypes: float64(1), object(14)\n",
      "memory usage: 787.6+ KB\n"
     ]
    }
   ],
   "source": [
    "borrado.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e31cf",
   "metadata": {},
   "source": [
    "Remplazo los \"nan\" por \"Unkown\" para cada una de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "81a37096",
   "metadata": {},
   "outputs": [],
   "source": [
    "borrado[\"Date\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Year\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Type\"].fillna((\"Invalid\"), inplace=True)\n",
    "borrado[\"Country\"].fillna((\"Unknown\"),inplace=True)\n",
    "borrado[\"Area\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Location\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Activity\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Name\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Sex \"].fillna((\"Unknown\"),inplace=True)\n",
    "borrado[\"Age\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Injury\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Fatal (Y/N)\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Time\"].fillna((\"Unknown\"), inplace=True)\n",
    "borrado[\"Species \"].fillna((\"Unknow\"), inplace=True)\n",
    "borrado[\"Investigator or Source\"].fillna((\"Unknown\"),inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f71219",
   "metadata": {},
   "source": [
    "Voy a empezar a armonizar los elementos de cada columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d1ff0",
   "metadata": {},
   "source": [
    "Empiezo por la columna de \"Sex\".\n",
    "- Compruebo los valores únicos de la columna \"Sex\".\n",
    "- Sustituyo la \"M con espacio\" por la \"M normal\". El resto las replazo por \"unkonwn\" y me quedo únicamente por M y F. \n",
    "- Compruebo de nuevo los valores únicos de \"Sex\" y veo que se han reducido a:\"F\",\"M\",\"nan\" y \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0cb74bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borrado[\"Sex \"].unique()\n",
    "\n",
    "df2=borrado.replace({'M ':'M','lli':'Unknown','N':'Unknown','.':'Unknown'})\n",
    "\n",
    "df2[\"Sex \"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd8d5c",
   "metadata": {},
   "source": [
    "Continúo con la columa \"Species\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8ddf842f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "especies=df2[\"Species \"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "19d4a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ww](hite|HITE).*\",\"White shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Tt](iger|IGER).*\",\"Tiger shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ll](emon|EMON).*\",\"Lemon shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Hh](ammerhead|AMMERHEAD).*\",\"Hammerhead shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Bb](ull|ULL).*\",\"Bull shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Bb](lue|LUE).*\",\"Blue shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](ilvertip|ILVERTIP).*\",\"Silvertip shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Nn](urse|URSE).*\",\"Nurse shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ww](haler|HALER).*\",\"Whaler shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Bb](lacktip|LACKTIP).*\",\"Blacktip shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[MM](ako|AKO).*\",\"Mako shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](and|AMD).*\",\"Sand shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ww](obbegong|OBBEGONG).*\",\"Wobbegong shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Gg](alapagos|ALAPAGOS).*\",\"Galapagos shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Gg](rey|REY).*\",\"Grey shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ll](eopard|EOPARD).*\",\"Leopard shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Zz](ambesi|AMBESI).*\",\"Zambesi shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Bb](lacktail|LACKTAIL).*\",\"Blacktail shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Rr](ed|ED).*\",\"Red shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Dd](usky|USKY).*\",\"Dusky shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Rr](aggedtooth|AGGEDTOOTH).*\",\"Raggedtooth shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](pinner|PINNER).*\",\"Spinner shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Cc](ow|OW).*\",\"Cow shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Pp](orbeagle|ORBEAGLE).*\",\"Porbeagle shark\",regex=True)\n",
    "#df2[\"Species \"]= df2[\"Species \"].str.replace(\"[^.?!]*Bronze[^.?!]*\",\"Bronze whaler shark\",regex=True) #este no sale cuando filtro por \"Bronze whaler shark\". Ahora me desaparece Bronze directamente...\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Cc](aribbean|ARIBBEAN).*\",\"Caribbean reef shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](and|AND).*\",\"Sandbar shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](ilky|ILKY).*\",\"Silky shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Zz](ambezi|AMBEZI).*\",\"Zambezi shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](evengill|EVENGILL).*\",\"Sevengill shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Cc](opper|OPPER).*\",\"Copper shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Aa](ngel|NGEL)\\s\",\"Angel shark\",regex=True) #lo he puesto diferente para que no pille \"los ángeles\" aún así parece que no ha funcionado.\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Ss](almon|ALMON).*\",\"Salmon shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Gg](oblin|OBLIN).*\",\"Goblin shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Tt](hresher|HRESHER).*\",\"Thresher shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\".*[Dd](ogfish|OGFISH).*\",\"Dogfish shark\",regex=True)\n",
    "df2[\"Species \"]= df2[\"Species \"].str.replace(\"[^.?!]*involvement[^.?!]*\",\"Involvement not confirmed\",regex=True)#no funciona\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc56a6a",
   "metadata": {},
   "source": [
    "Saco los valores únicos tras la agruapación y los convierto en lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "19851ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "especieslimpio=df2[\"Species \"].unique()\n",
    "especieslimpio\n",
    "len(especieslimpio)\n",
    "listaespecieslimpio=list(especieslimpio)\n",
    "#print(listaespecieslimpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e248c",
   "metadata": {},
   "source": [
    "Usando \"value.counts\", obtengo la frecuencia de cada uno de los valores únicos que he obtenido en el paso anterior y la meto en una variable lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2c4d7ae2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frecuencia_especies=list(df2[\"Species \"].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af2b19",
   "metadata": {},
   "source": [
    "Ahora me creo una lista solo con las frecuencias que son igual a 1. Entiendo que serán los valores que quedan sin armonizar y que quiero meter bajo el nombre genérico \"Unkown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b3fca567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista2=[]\n",
    "for i in range(len(frecuencia_especies)):\n",
    "    if frecuencia_especies[i]==1:\n",
    "        lista2.append(frecuencia_especies[i])\n",
    "#print(lista2)\n",
    "#len(frecuencia_especies)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db7844",
   "metadata": {},
   "source": [
    "Utilizando la función zip con la lista de los valores únicos de la columna Especies y la lista de las frecuencias de las especies, hago un diccionario en el que figura cada uno de los elementos de la columna especie como key y su frecuencia como value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5b9a0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_ = {}\n",
    "for especieslimpio,frecuencia_especies in zip(especieslimpio,frecuencia_especies):\n",
    "    dicc_[especieslimpio] = frecuencia_especies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ae20bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dicc_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba19e6c",
   "metadata": {},
   "source": [
    "El siguiente paso es filtrar aquellos pares cuyo value sea 1. Luego, obtengo las keys y la convierto en lista. Entonces, ya tendría todos los elementos que quiero renombrar con \"Unkown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "42ce212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "especiesunkown=dict(filter(lambda x: x[1] == 1, dicc_ .items()))\n",
    "type(especiesunkown)\n",
    "#print(especiesunkown)\n",
    "listaespeciesunkown=list(especiesunkown.keys())\n",
    "#print((listaespeciesunkown))\n",
    "#type(listaespeciesunkown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706df930",
   "metadata": {},
   "source": [
    "Construyo una función que recibe dos listas de tamaños diferentes. En este caso, la lista de valores únicos de la columna Especies (la mayor) y otra lista con los valores que quiero sustituir por Unkown (la menor). La función me tiene que devolver la lista de los valores únicos con los elementos de la lista menor reemplazados por \"unkown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4f7bcb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sustituir(s,b):\n",
    "    #for i,p in enumerate(s):\n",
    "       # if p in b:\n",
    "            #b[i]=\"unkown\"\n",
    "   # return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc63c6d",
   "metadata": {},
   "source": [
    "Con la lista que me devuelve la función, trataría de machacar la columna Especies ya existente. No sé si se podría utilizar .apply o si sería mejor crear una columna nueva y asignarles los valores de la lista resultante de la función para ya luego borrar la columna original de Especies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a0f876bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'src.cleaning_functions' has no attribute 'sustituir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-76e043179752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Species\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Species \"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msustituir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#SOS!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'src.cleaning_functions' has no attribute 'sustituir'"
     ]
    }
   ],
   "source": [
    "df2[\"Species\"]=df2[\"Species \"].apply(cf.sustituir) #SOS!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3cbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7ebb6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                           971\n",
       "Swimming                          869\n",
       "Unknown                           550\n",
       "Fishing                           431\n",
       "Spearfishing                      332\n",
       "Bathing                           162\n",
       "Wading                            149\n",
       "Diving                            127\n",
       "Standing                           99\n",
       "Snorkeling                         89\n",
       "Scuba diving                       76\n",
       "Body boarding                      61\n",
       "Body surfing                       49\n",
       "Swimming                           47\n",
       "Kayaking                           33\n",
       "Fell overboard                     32\n",
       "Treading water                     32\n",
       "Pearl diving                       32\n",
       "Boogie boarding                    29\n",
       "Free diving                        29\n",
       "Windsurfing                        19\n",
       "Walking                            17\n",
       "Boogie Boarding                    16\n",
       "Shark fishing                      15\n",
       "Floating                           14\n",
       "Canoeing                           13\n",
       "Fishing                            13\n",
       "Surf fishing                       12\n",
       "Surf-skiing                        12\n",
       "Boating                            12\n",
       "Rowing                             12\n",
       "Surf skiing                        12\n",
       "Kayak Fishing                      11\n",
       "Fishing for sharks                 11\n",
       "Sponge diving                      10\n",
       "Freediving                         10\n",
       "Scuba Diving                       10\n",
       "Sailing                             9\n",
       "Sitting on surfboard                9\n",
       "Fell into the water                 9\n",
       "Diving for trochus                  9\n",
       "Paddle boarding                     8\n",
       "Sea disaster                        8\n",
       "Skindiving                          7\n",
       "Surfing (sitting on his board)      7\n",
       "Spearfishing                        7\n",
       "Diving for abalone                  7\n",
       "Surf skiing                         7\n",
       "Floating on his back                7\n",
       "Playing                             7\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df2[\"Activity\"].unique()) # Usar redex. Por ejemplo: donde me encuentre swim sustituye por swimming y así voy creando menos categorías usando replace el metodo de redex por lo otro. str.replace. Las cosas raras que no pueda incluir en ninguna categoría, las pongo como \"others\"\n",
    "df2[\"Activity\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d7e7f",
   "metadata": {},
   "source": [
    "Obtengo los valores únicos de la columa Países:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e0dabdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'MEXICO', 'BRAZIL', 'ENGLAND', 'SOUTH AFRICA',\n",
       "       'THAILAND', 'COSTA RICA', 'MALDIVES', 'BAHAMAS', 'NEW CALEDONIA',\n",
       "       'ECUADOR', 'MALAYSIA', 'LIBYA', 'Unknown', 'CUBA', 'MAURITIUS',\n",
       "       'NEW ZEALAND', 'SPAIN', 'SAMOA', 'SOLOMON ISLANDS', 'JAPAN',\n",
       "       'EGYPT', 'ST HELENA, British overseas territory', 'COMOROS',\n",
       "       'REUNION', 'FRENCH POLYNESIA', 'UNITED KINGDOM',\n",
       "       'UNITED ARAB EMIRATES', 'PHILIPPINES', 'INDONESIA', 'CHINA',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'Fiji', 'DOMINICAN REPUBLIC',\n",
       "       'CAYMAN ISLANDS', 'ARUBA', 'MOZAMBIQUE', 'FIJI', 'PUERTO RICO',\n",
       "       'ITALY', 'ATLANTIC OCEAN', 'GREECE', 'ST. MARTIN', 'FRANCE',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'NIGERIA', 'TONGA', 'SCOTLAND',\n",
       "       'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE', 'ANTIGUA', 'KENYA',\n",
       "       'RUSSIA', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)', 'AZORES',\n",
       "       'SOUTH KOREA', 'MALTA', 'VIETNAM', 'MADAGASCAR', 'PANAMA',\n",
       "       'SOMALIA', 'NEVIS', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL',\n",
       "       'YEMEN', 'GULF OF ADEN', 'Sierra Leone', 'ST. MAARTIN',\n",
       "       'GRAND CAYMAN', 'Seychelles', 'LIBERIA', 'VANUATU', 'MEXICO ',\n",
       "       'HONDURAS', 'VENEZUELA', 'SRI LANKA', ' TONGA', 'URUGUAY', 'INDIA',\n",
       "       'MICRONESIA', 'CARIBBEAN SEA', 'OKINAWA', 'TANZANIA',\n",
       "       'MARSHALL ISLANDS', 'EGYPT / ISRAEL', 'NORTHERN ARABIAN SEA',\n",
       "       'HONG KONG', 'EL SALVADOR', 'ANGOLA', 'BERMUDA', 'MONTENEGRO',\n",
       "       'IRAN', 'TUNISIA', 'NAMIBIA', 'NORTH ATLANTIC OCEAN', 'PORTUGAL',\n",
       "       'SOUTH CHINA SEA', 'BANGLADESH', 'PALAU', 'WESTERN SAMOA',\n",
       "       'PACIFIC OCEAN ', 'BRITISH ISLES', 'GRENADA', 'IRAQ', 'TURKEY',\n",
       "       'SINGAPORE', 'NEW BRITAIN', 'SUDAN', 'JOHNSTON ISLAND',\n",
       "       'SOUTH PACIFIC OCEAN', 'NEW GUINEA', 'RED SEA',\n",
       "       'NORTH PACIFIC OCEAN', 'FEDERATED STATES OF MICRONESIA',\n",
       "       'MID ATLANTIC OCEAN', 'ADMIRALTY ISLANDS', 'BRITISH WEST INDIES',\n",
       "       'SOUTH ATLANTIC OCEAN', 'PERSIAN GULF', 'RED SEA / INDIAN OCEAN',\n",
       "       'PACIFIC OCEAN', 'NORTH SEA', 'NICARAGUA ', 'MALDIVE ISLANDS',\n",
       "       'AMERICAN SAMOA', 'ANDAMAN / NICOBAR ISLANDAS', 'GABON', 'MAYOTTE',\n",
       "       'NORTH ATLANTIC OCEAN ', 'THE BALKANS', 'SUDAN?', 'ARGENTINA',\n",
       "       'MARTINIQUE', 'INDIAN OCEAN', 'GUATEMALA', 'NETHERLANDS ANTILLES',\n",
       "       'NORTHERN MARIANA ISLANDS', 'IRAN / IRAQ', 'JAVA', 'SIERRA LEONE',\n",
       "       ' PHILIPPINES', 'NICARAGUA', 'CENTRAL PACIFIC',\n",
       "       'SOLOMON ISLANDS / VANUATU', 'SOUTHWEST PACIFIC OCEAN',\n",
       "       'BAY OF BENGAL', 'MID-PACIFC OCEAN', 'SLOVENIA', 'CURACAO',\n",
       "       'ICELAND', 'ITALY / CROATIA', 'BARBADOS', 'MONACO', 'GUYANA',\n",
       "       'HAITI', 'SAN DOMINGO', 'IRELAND', 'KUWAIT', 'YEMEN ',\n",
       "       'REUNION ISLAND', 'FALKLAND ISLANDS', 'CRETE', 'CYPRUS', 'EGYPT ',\n",
       "       'WEST INDIES', 'BURMA', 'LEBANON', 'PARAGUAY',\n",
       "       'BRITISH NEW GUINEA', 'CEYLON', 'OCEAN', 'GEORGIA', 'SYRIA',\n",
       "       'TUVALU', 'INDIAN OCEAN?', 'GUINEA', 'ANDAMAN ISLANDS',\n",
       "       'EQUATORIAL GUINEA / CAMEROON', 'COOK ISLANDS', 'TOBAGO', 'PERU',\n",
       "       'AFRICA', 'ALGERIA', 'Coast of AFRICA', 'TASMAN SEA', 'GHANA',\n",
       "       'GREENLAND', 'MEDITERRANEAN SEA', 'SWEDEN', 'ROATAN',\n",
       "       'Between PORTUGAL & INDIA', 'DJIBOUTI', 'BAHREIN', 'KOREA',\n",
       "       'RED SEA?', 'ASIA?', 'CEYLON (SRI LANKA)'], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc39a8a",
   "metadata": {},
   "source": [
    "Ahora usando \".apply\" importo y aplico la función que he creado en \"Cleaning_functions.py\"para determinar si cada país de la columna Country pertenece al Hemisferio Norte o al Hemisferio Sur y veo que efectivamente se crea otra columna llamada Hemisferio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "7621df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Hemisphere\"] = df2[\"Country\"].apply(cf.hemisferio) \n",
    "#no me pilla el import de mi hoja de funciones de visual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0ebfbaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>Hemisphere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>Hemisferio norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>Unknow</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>Hemisferio norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>07h45</td>\n",
       "      <td>Unknow</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>Hemisferio norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>Hemisferio sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>Hemisferio norte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    Year        Type    Country             Area  \\\n",
       "0  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex       Age  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F       57   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F       11   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M       48   \n",
       "3              Arrawarra Headland      Surfing             male    M  Unknown   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  Unknown   \n",
       "\n",
       "                                              Injury Fatal (Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...     Unknown   \n",
       "1                         Minor injury to left thigh     Unknown   \n",
       "2       Injury to left lower leg from surfboard skeg     Unknown   \n",
       "3                          Minor injury to lower leg     Unknown   \n",
       "4  Lacerations to leg & hand shark PROVOKED INCIDENT     Unknown   \n",
       "\n",
       "            Time     Species           Investigator or Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00       Unknow  K.McMurray, TrackingSharks.com   \n",
       "2          07h45       Unknow  K.McMurray, TrackingSharks.com   \n",
       "3        Unknown    2 m shark                  B. Myatt, GSAF   \n",
       "4        Unknown  Tiger shark                       A .Kipper   \n",
       "\n",
       "         Hemisphere  \n",
       "0  Hemisferio norte  \n",
       "1  Hemisferio norte  \n",
       "2  Hemisferio norte  \n",
       "3    Hemisferio sur  \n",
       "4  Hemisferio norte  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "50ad5949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florida                                 1037\n",
       "New South Wales                          486\n",
       "Unknown                                  455\n",
       "Queensland                               311\n",
       "Hawaii                                   297\n",
       "                                        ... \n",
       "Ysabel Island                              1\n",
       " Lau Province                              1\n",
       "South Coast, East New Britain              1\n",
       "Between Southampton & Canary Islands       1\n",
       "Moala Island                               1\n",
       "Name: Area, Length: 826, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Area\"].unique()\n",
    "df2[\"Area\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea0b2b",
   "metadata": {},
   "source": [
    "Veo cuáles son los valores únicos de la columna \"Type\" y luego hago replace para armonizar sus elementos y reducirlos a 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c16f37a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4594\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boating          341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tipo=df2[\"Type\"].unique()\n",
    "df2[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2d93e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace({\"Questionable\":\"Invalid\",\"Boat\":\"Boating\",\"Boatomg\":\"Boating\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "82f97aee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4594\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boating          341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c2b14",
   "metadata": {},
   "source": [
    "Regularizo la columna nombre: veo que, al hacer los valores únicos, hay muchos valores que no son nombres reales y que se repiten mucho. He decidido que todos aquellos valores que se repitan más de 3 veces, los voy a sustituir por \"Unkown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f8c42ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nombres=list(df2[\"Name\"].unique())\n",
    "#print(nombres)\n",
    "frecuencianombres=list(df2[\"Name\"].value_counts(sort=False)) #Podemos incluir el parámetro \"Sort=False\" para que no me ordene la frecuenecia con la que aparecen los valores únicos de forma descendente y lo deje en el miso orden que aparecen en el dataframe.\n",
    "#print(frecuencianombres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2e1ca13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_nombre = {}\n",
    "for nombres,frecuencianombres in zip(nombres,frecuencianombres):\n",
    "    dicc_nombre[nombres] = frecuencianombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0f74ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dicc_nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6a607976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male', 'female', 'Unknown', 'girl', 'child', 'boy', '2 males', 'Unidentified', 'Anonymous', 'black male', '2 fishermen', 'a soldier', 'boat', 'fisherman', 'a pearl diver', 'sailor', 'a sailor', 'males', 'a native', 'Arab boy']\n"
     ]
    }
   ],
   "source": [
    "nombresunkown=dict(filter(lambda x: x[1] > 3, dicc_nombre.items()))\n",
    "type(nombresunkown)\n",
    "#rint(nombresunkown)\n",
    "listanombresunkown=list(nombresunkown.keys())\n",
    "print((listanombresunkown))\n",
    "#type(listanombresunkown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad297b5",
   "metadata": {},
   "source": [
    "Ahora utilizaría la función \"sustituir\" creada anteriormente para otra columna y con la lista que me devuelve la función, trataría de machacar la columna \"Name\" ya existente. No sé si se podría utilizar .apply o si sería mejor crear una columna nueva y asignarles los valores de la lista resultante de la función para ya luego borrar la columna original de Name. **Luego podría quizás depurar un poco más eseta columna con Regex quitando sustituyendo por \"Unkown\" aquellos elementos que contengan \"male\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe705e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38133416",
   "metadata": {},
   "source": [
    "Ahora voy a ver los valores únicos de la columna \"Fatal (Y/N)\", dejando únicamente 3:Y,N y Unkown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9d6a658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    4903\n",
       "Y          1389\n",
       "N             7\n",
       "Unkown        2\n",
       "Name: Fatal (Y/N), dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Fatal (Y/N)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2a3bfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace({\"UNKNOWN\":\"Unknown\",\" N\":\"N\",\"y\":\"Y\",\"M\":\"Unknown\",\"2017\":\"Unknown\",\"N \":\"Unknown\",\"Unkown\":\"Unknown\" },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bedefd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    4905\n",
       "Y          1389\n",
       "N             7\n",
       "Name: Fatal (Y/N), dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Fatal (Y/N)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494c4c3",
   "metadata": {},
   "source": [
    "Busco los valores únicos de la columna \"Injury\" y, mediante el uso de Regex, sustituyo los valores armonizados para disminuir el número de valores únicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "adda8bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No injury', 'Minor injury to left thigh',\n",
       "       'Injury to left lower leg from surfboard skeg', ...,\n",
       "       'FATAL, leg stripped of flesh  ',\n",
       "       'FATAL, knocked overboard by tail of shark & carried off by shark ',\n",
       "       'FATAL. \"Shark bit him in half, carrying away the lower extremities\" '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Injury\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c8bfc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Nn](o|O)\\s*[Ii](njury|NJURY).*\",\"No injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Mm](inor|INOR)\\s*[Ii](njury|NJURY|njuries|NJURIES|ed|ED).*\",\"Minor Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Hh](and|AND).*\",\"Hand injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ll](eg|EG).*\",\"Leg injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ll](aceration|ACERATION).*\",\"Laceration\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ff](atal|ATAL).*\",\"Fatal\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ff](oot|OOT).*\",\"Foot Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Aa](nkle|NKLE).*\",\"Ankle Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ss](houlder|HOULDER).*\",\"Shoulder Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Aa](brasion|BRASION).*\",\"Abrasion Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Cc](alf|ALF).*\",\"Calf Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Tt](orso|ORSO).*\",\"Torso Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ff](eet|EET).*\",\"Feet Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Tt](high|HIGH).*\",\"Thigh Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Aa](rm|RM)\\s*[Ii](njury|NJURY).*\",\"Arm injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Pp](uncture|UNCTURE)\\s*[Ww](ounds|OUNDS).*\",\"Puncture wounds\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Kk](nee|NEE).*\",\"Knee Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Cc](hest|HEST).*\",\"Chest Injury\",regex=True)\n",
    "df2[\"Injury\"]=df2[\"Injury\"].str.replace(\".*[Ee](lbow|LBOW).*\",\"Elbow Injury\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f59f7",
   "metadata": {},
   "source": [
    "Aquí tendría que hacer la función remplazar para esta columna también..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1312b",
   "metadata": {},
   "source": [
    "En resumen, he limpiado los datos de las siguientes columnas:\n",
    "- Year:acaban en punto 0, quizás podría quitarse.\t\n",
    "- Type: he dejado 5 valores únicos(Unprovoked, provoked, Invalid, Boating, Sea Disaster).\t\n",
    "- Country: la he utilizado para crear la columna \"Hemisphere\".\t\t\n",
    "- Activity: Bea.\n",
    "- Name: he dejado aquellos elementos que se repiten menos de 4 veces e importo con la función \"sustituir). Quizás luego depure con Regex.\t\n",
    "- Sex: he dejado 3 valores únicos(F/M/Unknown).\t\n",
    "- Injury: regularizado con Regex e importado con una función(sustituir).\n",
    "- Fatal (Y/N): he dejado 3 valores únicos(Y/N/Unknown).\t\n",
    "- Species:regularizado con Regex e importado con una función(sustituir).\n",
    "- Hemisphere: he creado esta columna con la función hemisferio.\n",
    "\n",
    "He dejado tal cual estaban las siguientes columnas:\n",
    "- Investigator or Source.\n",
    "- Area.\n",
    "- Age.\n",
    "- Time.\n",
    "- Location\n",
    "- Date\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
